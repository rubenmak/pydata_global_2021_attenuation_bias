{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/attenuation/lib/python3.8/site-packages (1.21.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in ./venv/attenuation/lib/python3.8/site-packages (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/attenuation/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in ./venv/attenuation/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/attenuation/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in ./venv/attenuation/lib/python3.8/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in ./venv/attenuation/lib/python3.8/site-packages (from scipy) (1.21.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pymc3 in ./venv/attenuation/lib/python3.8/site-packages (3.11.4)\n",
      "Requirement already satisfied: semver>=2.13.0 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (2.13.0)\n",
      "Requirement already satisfied: theano-pymc==1.1.2 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (1.21.2)\n",
      "Requirement already satisfied: cachetools>=4.2.1 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (4.2.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (3.10.0.2)\n",
      "Requirement already satisfied: dill in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (0.3.4)\n",
      "Requirement already satisfied: arviz>=0.11.0 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (0.11.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (0.5.2)\n",
      "Requirement already satisfied: fastprogress>=0.2.0 in ./venv/attenuation/lib/python3.8/site-packages (from pymc3) (1.0.0)\n",
      "Requirement already satisfied: filelock in ./venv/attenuation/lib/python3.8/site-packages (from theano-pymc==1.1.2->pymc3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas>=0.24.0->pymc3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas>=0.24.0->pymc3) (2021.3)\n",
      "Requirement already satisfied: packaging in ./venv/attenuation/lib/python3.8/site-packages (from arviz>=0.11.0->pymc3) (21.0)\n",
      "Requirement already satisfied: netcdf4 in ./venv/attenuation/lib/python3.8/site-packages (from arviz>=0.11.0->pymc3) (1.5.7)\n",
      "Requirement already satisfied: setuptools>=38.4 in ./venv/attenuation/lib/python3.8/site-packages (from arviz>=0.11.0->pymc3) (41.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.0 in ./venv/attenuation/lib/python3.8/site-packages (from arviz>=0.11.0->pymc3) (3.4.3)\n",
      "Requirement already satisfied: xarray>=0.16.1 in ./venv/attenuation/lib/python3.8/site-packages (from arviz>=0.11.0->pymc3) (0.19.0)\n",
      "Requirement already satisfied: six in ./venv/attenuation/lib/python3.8/site-packages (from patsy>=0.5.1->pymc3) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./venv/attenuation/lib/python3.8/site-packages (from packaging->arviz>=0.11.0->pymc3) (2.4.7)\n",
      "Requirement already satisfied: cftime in ./venv/attenuation/lib/python3.8/site-packages (from netcdf4->arviz>=0.11.0->pymc3) (1.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pymc3) (8.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pymc3) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib>=3.0->arviz>=0.11.0->pymc3) (0.10.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: seaborn in ./venv/attenuation/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in ./venv/attenuation/lib/python3.8/site-packages (from seaborn) (1.21.2)\n",
      "Requirement already satisfied: scipy>=1.0 in ./venv/attenuation/lib/python3.8/site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23 in ./venv/attenuation/lib/python3.8/site-packages (from seaborn) (1.3.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in ./venv/attenuation/lib/python3.8/site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/attenuation/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/attenuation/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: statsmodels in ./venv/attenuation/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: pandas>=0.25 in ./venv/attenuation/lib/python3.8/site-packages (from statsmodels) (1.3.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in ./venv/attenuation/lib/python3.8/site-packages (from statsmodels) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.3 in ./venv/attenuation/lib/python3.8/site-packages (from statsmodels) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/attenuation/lib/python3.8/site-packages (from statsmodels) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas>=0.25->statsmodels) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/attenuation/lib/python3.8/site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: six in ./venv/attenuation/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install scipy\n",
    "!{sys.executable} -m pip install pymc3\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, odr\n",
    "import statsmodels.api as sm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def print_confidence_interval(param, stdev, alpha=0.05):\n",
    "    confidence_interval = np.array([param] * 2) + \\\n",
    "                        stats.norm.ppf(1-alpha/2) * np.multiply([-1, 1], [stdev] * 2)\n",
    "\n",
    "    print('[{0:.3f}\t{1:.3f}]'.format(alpha/2, 1-alpha/2))\n",
    "    print(' {0:.3f}\t{1:.3f}'.format(confidence_interval[0], confidence_interval[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p class=\"gap2\">\n",
    "<h1 style=\"font-weight: bold; color: #ed9041\">Some Attention for Attenuation Bias<br>\n",
    "</h1>\n",
    "\n",
    "<h2 style=\"color: #667b83\">And how we account for it in geo experiments</h2>\n",
    "\n",
    "\n",
    "<p class=\"gap05\">  </p>\n",
    "<h3 style=\"color: #459db9\">Ruben Mak <br>\n",
    "Principal Data Scientist at Greenhouse</h3>\n",
    "<img src=\"images/pydata_global_logo.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Short introduction\n",
    "\n",
    "<p><img src=\"images/wpp_greenhouse.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/bias.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perspective on bias for this talk\n",
    "* Computing something different than you intent to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Attenuation bias\n",
    "* You want to compute: $\\hat{\\beta}$ in $y = \\alpha + \\beta x + \\epsilon_y$ \n",
    "* $\\epsilon_y \\sim \\mathcal{N}(0,\\sigma_y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* But you are not observing the true $x$ but $\\tilde{x} = x + \\epsilon_x$\n",
    "* $\\epsilon_x \\sim \\mathcal{N}(0,\\sigma_x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* So you are computing $\\hat{\\beta}$ in$y=\\alpha+\\beta(x+\\epsilon_x)+\\epsilon_y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Attenuation Bias = Measurement Error Bias = Regression Dilution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "洧띺 = 0 \n",
    "洧띻 = 2.5\n",
    "洧랥洧녽 = 洧랥洧논 = 1\n",
    "size = 10000\n",
    "\n",
    "true_洧논 = np.random.normal(loc=5, scale=1, size=size)\n",
    "洧논 = true_洧논 + np.random.normal(loc=0, scale=洧랥洧논, size=size)\n",
    "洧녽 = 洧띺 + 洧띻 * true_洧논 + np.random.normal(loc=0, scale=洧랥洧녽, size=size)\n",
    "\n",
    "X = sm.add_constant(洧논)\n",
    "model = sm.OLS(洧녽,X)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025\t0.975]\n",
      " 1.226\t1.283\n",
      "洧띻 = 2.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.430</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.430</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7543.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Oct 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:59:00</td>     <th>  Log-Likelihood:    </th> <td> -21271.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>4.255e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9998</td>      <th>  BIC:               </th> <td>4.256e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    6.2821</td> <td>    0.075</td> <td>   83.930</td> <td> 0.000</td> <td>    6.135</td> <td>    6.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.2545</td> <td>    0.014</td> <td>   86.851</td> <td> 0.000</td> <td>    1.226</td> <td>    1.283</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.707</td> <th>  Durbin-Watson:     </th> <td>   1.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.157</td> <th>  Jarque-Bera (JB):  </th> <td>   3.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.037</td> <th>  Prob(JB):          </th> <td>   0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.058</td> <th>  Cond. No.          </th> <td>    19.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.430\n",
       "Model:                            OLS   Adj. R-squared:                  0.430\n",
       "Method:                 Least Squares   F-statistic:                     7543.\n",
       "Date:                Fri, 29 Oct 2021   Prob (F-statistic):               0.00\n",
       "Time:                        17:59:00   Log-Likelihood:                -21271.\n",
       "No. Observations:               10000   AIC:                         4.255e+04\n",
       "Df Residuals:                    9998   BIC:                         4.256e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          6.2821      0.075     83.930      0.000       6.135       6.429\n",
       "x1             1.2545      0.014     86.851      0.000       1.226       1.283\n",
       "==============================================================================\n",
       "Omnibus:                        3.707   Durbin-Watson:                   1.977\n",
       "Prob(Omnibus):                  0.157   Jarque-Bera (JB):                3.693\n",
       "Skew:                          -0.037   Prob(JB):                        0.158\n",
       "Kurtosis:                       3.058   Cond. No.                         19.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_confidence_interval(results.params[1], np.sqrt(results.cov_params()[1,1]))\n",
    "print('洧띻 = {}'.format(洧띻))\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to be aware of potential attenuation bias?\n",
    "* There might be noise in your observed $\\tilde{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* You care about what happens to $y$ when true $x$ changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* You're doing inference, not plain prediction or classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Are you doing inference?\n",
    "* Let me illustrate with a short story..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/scenario_1.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/scenario_2.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/scenario_3.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/scenario_4.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/scenario_5.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond linear models\n",
    "* More general, you want to know what happens to $y$ when true $x$ is changed: $\\delta_y = \\mathbb{E}(y | x=v_2, z) - \\mathbb{E}(y | x=v_1, z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Relation to causal inference $\\mathbb{P}(Y | X) \\neq \\mathbb{P}(Y | Do(X))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reasons why I think attenuation bias is overlooked\n",
    "* Focus on prediction / machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Academia are conservative in rejecting the $H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The direction of attenuation bias\n",
    "* Attenuation bias is always towards zero: $E(|\\hat{\\beta}|) < |\\beta|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Academia: if we find a significant effect without accounting for attenuation bias, the effect is also significant when accounting for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Academia: but if we incorrectly account for attenuation bias, we might be falsely rejecting $H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* But in practice, underestimation can be just as costly as overestimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accounting for attenuation bias\n",
    "* Deming Regression, Orthogonal (Distance) Regression (ODR), Total Least Squares (TLS): same family of solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Error-in-Variables models, flexible Bayesian version using latent variables. Includes applications in deep learning ([May 2021](https://arxiv.org/abs/2105.09095))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In my experience, Error-in-Variables models can be quite sensitive to model specification. See [this notebook](https://github.com/rubenmak/pydata_global_2021_attenuation_bias/blob/master/Bayesian_EiV_is_biased.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Our proposed solution for binary treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025\t0.975]\n",
      " 2.411\t2.507\n",
      "洧띻 = 2.5\n"
     ]
    }
   ],
   "source": [
    "from scipy import odr\n",
    "\n",
    "洧띺 = 0 \n",
    "洧띻 = 2.5\n",
    "洧랥洧녽 = 洧랥洧논 = 1\n",
    "size = 10000\n",
    "\n",
    "true_洧논 = np.random.normal(loc=5, scale=1, size=size)\n",
    "洧논 = true_洧논 + np.random.normal(loc=0, scale=洧랥洧논, size=size)\n",
    "洧녽 = 洧띺 + 洧띻 * true_洧논 + np.random.normal(loc=0, scale=洧랥洧녽, size=size)\n",
    "\n",
    "def f(B, x):\n",
    "    return B[0] + B[1]*x\n",
    "\n",
    "linear = odr.Model(f)\n",
    "mydata = odr.RealData(洧논, 洧녽)\n",
    "myodr = odr.ODR(mydata, linear, beta0=[1., 2.])\n",
    "\n",
    "results = myodr.run()\n",
    "# results.pprint()\n",
    "\n",
    "print_confidence_interval(results.beta[1], results.sd_beta[1])\n",
    "print('洧띻 = {}'.format(洧띻))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ODR / TLS assumptions\n",
    "* Here, we assume $\\sigma_x = \\sigma_y$\n",
    "* You need to at least know something about $\\sigma_x$, $\\sigma_y$ and/or $\\dfrac{\\sigma_x}{\\sigma_y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025\t0.975]\n",
      " 2.166\t2.245\n",
      "洧띻 = 2.5\n"
     ]
    }
   ],
   "source": [
    "洧띺 = 0 \n",
    "洧띻 = 2.5\n",
    "洧랥洧녽 = 0.1\n",
    "洧랥洧논 = 1\n",
    "size = 10000\n",
    "\n",
    "true_洧논 = np.random.normal(loc=5, scale=1, size=size)\n",
    "洧논 = true_洧논 + np.random.normal(loc=0, scale=洧랥洧논, size=size)\n",
    "y = 洧띺 + 洧띻 * true_洧논 + np.random.normal(loc=0, scale=洧랥洧녽, size=size)\n",
    "\n",
    "def f(B, x):\n",
    "    return B[0] + B[1]*x\n",
    "\n",
    "linear = odr.Model(f)\n",
    "mydata = odr.RealData(洧논, 洧녽)\n",
    "myodr = odr.ODR(mydata, linear, beta0=[1., 2.])\n",
    "\n",
    "results = myodr.run()\n",
    "# results.pprint()\n",
    "\n",
    "print_confidence_interval(results.beta[1], results.sd_beta[1])\n",
    "print('洧띻 = {}'.format(洧띻))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025\t0.975]\n",
      " 2.431\t2.526\n",
      "洧띻 = 2.5\n"
     ]
    }
   ],
   "source": [
    "洧띺 = 0 \n",
    "洧띻 = 2.5\n",
    "洧랥洧녽 = 0.1\n",
    "洧랥洧논 = 1\n",
    "size = 10000\n",
    "\n",
    "true_洧논 = np.random.normal(loc=5, scale=1, size=size)\n",
    "洧논 = true_洧논 + np.random.normal(loc=0, scale=洧랥洧논, size=size)\n",
    "y = 洧띺 + 洧띻 * true_洧논 + np.random.normal(loc=0, scale=洧랥洧녽, size=size)\n",
    "\n",
    "def f(B, x):\n",
    "    return B[0] + B[1]*x\n",
    "\n",
    "linear = odr.Model(f)\n",
    "mydata = odr.RealData(洧논, 洧녽, sx=洧랥洧논, sy=洧랥洧녽)\n",
    "myodr = odr.ODR(mydata, linear, beta0=[1., 2.])\n",
    "\n",
    "results = myodr.run()\n",
    "# results.pprint()\n",
    "\n",
    "print_confidence_interval(results.beta[1], results.sd_beta[1])\n",
    "print('洧띻 = {}'.format(洧띻))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geo Experiments\n",
    "* Make an assignment of treatments to different geographical regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Alternative to A/B test (Randomized Controlled Trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Reason 1: outcome cannot be measured in treated / non-treated groups, [Do mobile banner ads increase sales? Yes, in the offline channel](https://ink.library.smu.edu.sg/lkcsb_research/6243/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Reason 2: Impossible to measure non-treated outcome: Google Ads (Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/paid_organic.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geo Experiments\n",
    "\n",
    "* Google paper 2011 [Measuring Ad Effectiveness Using Geo Experiments](https://research.google/pubs/pub38355/)\n",
    "* Google paper mentioning orthogonal regression 2017 [Estimating Ad Effectiveness using Geo Experiments in a Time-Based Regression Framework](https://research.google/pubs/pub45950/)\n",
    "\n",
    "<p><img src=\"images/geo_dma.png\"></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>geo</th>\n",
       "      <th>treated</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  geo  treated  outcome\n",
       "0     0    0        0     1000\n",
       "1     0    1        0     1500\n",
       "2     1    0        0     1200\n",
       "3     1    1        1     2700"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/geo_data_1.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Attenuation Bias in Geo Experiments\n",
    "\n",
    "* Why do we have noise in $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* We want to know the effect of treatment $T$ (true $x$) but we observe geo ($\\tilde{x}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Reason 1: Different technologies used for estimating location, some are noisy (store, mobile phone, website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Reason 2: People move between treated and non-treated geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Under some assumptions, we have data to estimate $\\sigma_{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Proposed Solution\n",
    "* Simple but powerful trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Only works for binary $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Bernoulli distribution: $\\sigma^2 = p(1-p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Knowing $\\sigma_x$ implies $p_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>geo</th>\n",
       "      <th>treated</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  geo  treated  outcome\n",
       "0     0    0     0.00     1000\n",
       "1     0    1     0.00     1500\n",
       "2     1    0     0.15     1200\n",
       "3     1    1     0.85     2700"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/geo_data_2.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intuition\n",
    "* Geo's aren't fully treated / non-treated, but 'partly treated / non-treated'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generic example with binary treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025\t0.975]\n",
      " 1.737\t1.842\n",
      "洧띻 = 2.5\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "洧띺 = 0 \n",
    "洧띻 = 2.5\n",
    "洧랥洧녽 = 1\n",
    "洧녷洧논 = 0.85\n",
    "size = 10000\n",
    "      \n",
    "apply_noise = lambda x: 1 - x if random.uniform(0, 1) > 洧녷洧논 else x\n",
    "apply_noise = np.vectorize(apply_noise)\n",
    "        \n",
    "true_洧논 = np.random.binomial(n=1, p=0.5, size=size)\n",
    "洧논 = apply_noise(true_洧논)\n",
    "洧녽 = 洧띺 + 洧띻 * true_洧논 + np.random.normal(loc=0, scale=洧랥洧녽, size=size)\n",
    "\n",
    "X = sm.add_constant(洧논)\n",
    "model = sm.OLS(洧녽,X)\n",
    "results = model.fit()\n",
    "\n",
    "print_confidence_interval(results.params[1], np.sqrt(results.cov_params()[1,1]))\n",
    "print('洧띻 = {}'.format(洧띻))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025\t0.975]\n",
      " 2.403\t2.553\n",
      "洧띻 = 2.5\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "洧띺 = 0 \n",
    "洧띻 = 2.5\n",
    "洧랥洧녽 = 1\n",
    "洧녷洧논 = 0.85\n",
    "size = 10000\n",
    "      \n",
    "apply_noise = lambda x: 1 - x if random.uniform(0, 1) > 洧녷洧논 else x\n",
    "apply_noise = np.vectorize(apply_noise)\n",
    "      \n",
    "apply_p = lambda x: 洧녷洧논 if x == 1 else 1 - 洧녷洧논\n",
    "apply_p = np.vectorize(apply_p)\n",
    "        \n",
    "true_洧논 = np.random.binomial(n=1, p=0.5, size=size)\n",
    "洧논 = apply_noise(true_洧논)\n",
    "洧녷 = apply_p(洧논)\n",
    "洧녽 = 洧띺 + 洧띻 * true_洧논 + np.random.normal(loc=0, scale=洧랥洧녽, size=size)\n",
    "\n",
    "X = sm.add_constant(洧녷)\n",
    "model = sm.OLS(洧녽,X)\n",
    "results = model.fit()\n",
    "\n",
    "print_confidence_interval(results.params[1], np.sqrt(results.cov_params()[1,1]))\n",
    "print('洧띻 = {}'.format(洧띻))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025\t0.975]\n",
      " 3.539\t3.694\n",
      "洧띻 = 2.5\n",
      "洧랥洧논 = 0.357\n"
     ]
    }
   ],
   "source": [
    "洧띺 = 0 \n",
    "洧띻 = 2.5\n",
    "洧랥洧녽 = 1\n",
    "洧녷洧논 = 0.85\n",
    "洧랥洧논 = np.sqrt(洧녷洧논 * (1 - 洧녷洧논))\n",
    "size = 10000\n",
    "      \n",
    "apply_noise = lambda x: 1 - x if random.uniform(0, 1) > 洧녷洧논 else x\n",
    "apply_noise = np.vectorize(apply_noise)\n",
    "        \n",
    "true_洧논 = np.random.binomial(n=1, p=0.5, size=size)\n",
    "洧논 = apply_noise(true_洧논)\n",
    "洧녽 = 洧띺 + 洧띻 * true_洧논 + np.random.normal(loc=0, scale=洧랥洧녽, size=size)\n",
    "\n",
    "linear = odr.Model(f)\n",
    "mydata = odr.RealData(洧논, 洧녽, sx=洧랥洧논, sy=洧랥洧녽)\n",
    "myodr = odr.ODR(mydata, linear, beta0=[1., 2.])\n",
    "\n",
    "results = myodr.run()\n",
    "# results.pprint()\n",
    "\n",
    "print_confidence_interval(results.beta[1], results.sd_beta[1])\n",
    "print('洧띻 = {}'.format(洧띻))\n",
    "print('洧랥洧논 = {0:.3f}'.format(洧랥洧논))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications\n",
    "* We apply this trick for analysis of our geo experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Application in double machine learning and other methods for causal inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* When imputing missing data:\n",
    "    * Andrew Gelman suggests adding noise to make imputed data more realistic (Data Analysis Using Regression and Multilevel/Hierarchical Models)\n",
    "    * If you use the imputed variable for inference, you'll be introducing double attenuation bias!\n",
    "    * For binary variables, impute $p_x$ instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [How Using Machine Learning Classification as a Variable in Regression Leads to Attenuation Bias and What to Do About It, October 2021](https://osf.io/preprints/socarxiv/453jk/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to be aware of potential attenuation bias?\n",
    "* There might be noise in your observed $\\tilde{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* You care about what happens to $y$ when true $x$ changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* You're doing inference, not plain prediction or classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thanks!\n",
    "* Tobias Klein\n",
    "* Koen Graat\n",
    "* Ernst Osinga, Menno Zevenbergen, Mark van Zuijlen\n",
    "* Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pydata_global_2021_attenuation_bias.ipynb to slides\n",
      "[NbConvertApp] Writing 642937 bytes to pydata_global_2021_attenuation_bias.slides.html\n",
      "[NbConvertApp] Redirecting reveal.js requests to https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.5.0\n",
      "Serving your slides at http://127.0.0.1:8000/pydata_global_2021_attenuation_bias.slides.html\n",
      "Use Control-C to stop this server\n",
      "^C\n",
      "\n",
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert pydata_global_2021_attenuation_bias.ipynb --to slides --post serve"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "attenuation",
   "language": "python",
   "name": "attenuation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
